{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37540ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "# function of read data\n",
    "def _read_txt_(url):\n",
    "    file = open(url, 'r', encoding='utf-8')\n",
    "    seg_list = []\n",
    "    lines = file.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        seg_list.append(lines[i].rstrip(\"\\n\"))\n",
    "        pass\n",
    "    file.close()\n",
    "    return seg_list\n",
    "\n",
    "emit, trans, context = {},{},{}\n",
    "possible_tags = []\n",
    "#init\n",
    "context[\"<s>\"] = 0\n",
    "context[\"</s>\"] = 0\n",
    "\n",
    "train_list = _read_txt_(\"wiki-en-train.norm_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bed048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unique_list_(data):\n",
    "    unique_word_frequency = {}\n",
    "    for _, seq in enumerate(data):\n",
    "        wordtags = seq.split(\" \")\n",
    "        for _, wordtag in enumerate(wordtags):\n",
    "            word = wordtag.split(\"_\")[0]\n",
    "            if word not in unique_word_frequency:\n",
    "                unique_word_frequency[word] = 1\n",
    "            else:\n",
    "                num = unique_word_frequency[word]\n",
    "                unique_word_frequency[word] = num + 1\n",
    "    return unique_word_frequency\n",
    "\n",
    "def _UNK_(data, refer_dict):\n",
    "    for idx, seq in enumerate(data):\n",
    "        new_seq = \"\"\n",
    "        wordtags = seq.split(\" \")\n",
    "        for m, wordtag in enumerate(wordtags):\n",
    "            word, tag = wordtag.split(\"_\")[0], wordtag.split(\"_\")[1]\n",
    "            if word != \"UNK\" and refer_dict[word] < 3:\n",
    "                new = \"UNK_\" + tag\n",
    "                new_seq = new_seq + new + \" \"\n",
    "            else:\n",
    "                new_seq = new_seq + wordtag + \" \"\n",
    "        data[idx] = new_seq.rstrip(\" \")\n",
    "    return data\n",
    "unique_word_frequency = _unique_list_(train_list)\n",
    "train_list = _UNK_(train_list, unique_word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107ae0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "for seq in train_list:\n",
    "    previous = \"<s>\"\n",
    "    context[previous] += 1\n",
    "    wordtags = seq.split(\" \")\n",
    "    for wordtag in wordtags:\n",
    "        tmp = wordtag.split(\"_\")\n",
    "        word, tag = tmp[0], tmp[1]\n",
    "        if tag not in possible_tags:\n",
    "            possible_tags.append(tag)\n",
    "        # count the transtition\n",
    "        tmp_t = previous + \" \" + tag\n",
    "        if tmp_t not in trans.keys():\n",
    "            trans[tmp_t] = 1\n",
    "        else:\n",
    "            trans[tmp_t] += 1\n",
    "        # count the context\n",
    "        if tag not in context.keys():\n",
    "            context[tag] = 1\n",
    "        else:\n",
    "            context[tag] += 1\n",
    "        # count the emission\n",
    "        tmp_e = tag + \" \" + word\n",
    "        if tmp_e not in emit.keys():\n",
    "            emit[tmp_e] = 1\n",
    "        else:\n",
    "            emit[tmp_e] += 1\n",
    "        previous = tag\n",
    "    tmp_end = previous + \" </s>\"\n",
    "    context[\"</s>\"] +=1\n",
    "    if tmp_end not in trans.keys():\n",
    "        trans[tmp_end] = 1\n",
    "    else:\n",
    "        trans[tmp_end] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9b1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "trans_keys = list(trans.keys())\n",
    "emit_keys = list(emit.keys())\n",
    "test_list = _read_txt_(\"wiki-en-test.norm_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2bf507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3838\n",
      "4563\n"
     ]
    }
   ],
   "source": [
    "# p_example\n",
    "#-math.log(trans[\"JJ NN\"]/context[\"NN\"])\n",
    "#-math.log(emit[\"NN language\"]/context[\"NN\"])\n",
    "N = 0\n",
    "for seq in test_list:\n",
    "    wordtags = seq.split(\" \")\n",
    "    N = N + len(wordtags)\n",
    "denominator = 0\n",
    "numerator = 0\n",
    "for y, seq in enumerate(test_list):\n",
    "    best_score, best_edge = {},{}\n",
    "    best_score[\"0 <s>\"] = 0\n",
    "    best_edge[\"0 <s>\"] = None\n",
    "    wordtags = seq.split(\" \")\n",
    "    real_tags = []\n",
    "    for idx, wordtag in enumerate(wordtags):\n",
    "        if idx == len(wordtags) - 1: break\n",
    "        tmp = wordtag.split(\"_\")\n",
    "        word, tag = tmp[0], tmp[1]\n",
    "        if word not in unique_word_frequency:\n",
    "            word = \"UNK\"\n",
    "        real_tags.append(tag)\n",
    "        for i in range(len(possible_tags)):\n",
    "            previous = possible_tags[i]\n",
    "            if idx == 0 and i > 0:\n",
    "                break\n",
    "            for next_tag in possible_tags:\n",
    "                if idx == 0:\n",
    "                    previous = \"<s>\"    \n",
    "                    best_score_value = 0\n",
    "                else:\n",
    "                    if str(idx) + \" \" + previous in best_score.keys():\n",
    "                        best_score_value = best_score[str(idx) + \" \" + previous]\n",
    "                    else:\n",
    "                        continue\n",
    "                if previous + \" \" + next_tag in trans_keys:\n",
    "                    if next_tag + \" \" + word in emit_keys:\n",
    "                        score = best_score_value -\\\n",
    "                        math.log(trans[previous + \" \" + next_tag]/context[next_tag]) -\\\n",
    "                        math.log(emit[next_tag + \" \" + word]/context[next_tag])\n",
    "                    else:\n",
    "                        score = best_score_value -\\\n",
    "                        math.log(trans[previous + \" \" + next_tag]/context[next_tag]) -\\\n",
    "                        math.log(1/N)\n",
    "                    if str(idx+1)+\" \"+next_tag not in best_score.keys():\n",
    "                        best_score[str(idx+1)+\" \"+next_tag] = score\n",
    "                        best_edge[str(idx+1)+\" \"+next_tag] = word+\" \" + previous\n",
    "                    else:\n",
    "                        value = best_score[str(idx+1)+\" \"+next_tag]\n",
    "                        if score < value:\n",
    "                            best_score[str(idx+1)+\" \"+next_tag] = score\n",
    "                            best_edge[str(idx+1)+\" \"+next_tag] = word+\" \" + previous\n",
    "    tmp = wordtags[-1].split(\"_\")\n",
    "    word, tag = tmp[0], tmp[1]\n",
    "    if word not in unique_word_frequency:\n",
    "        word = \"UNK\"\n",
    "    real_tags.append(tag)\n",
    "    next_tag = \".\"\n",
    "    tmp_score = 10000\n",
    "    tmp_edge = None\n",
    "    for previous in possible_tags:\n",
    "        if str(len(wordtags)-1) + \" \" + previous in best_score.keys():\n",
    "            best_score_value = best_score[str(len(wordtags)-1) + \" \" + previous]\n",
    "        else:\n",
    "            continue\n",
    "        if (previous + \" \" + next_tag) in trans_keys:\n",
    "            if next_tag + \" \" + word in emit_keys:\n",
    "                score = best_score_value -\\\n",
    "                math.log(trans[previous + \" \" + next_tag]/context[next_tag]) -\\\n",
    "                math.log(emit[next_tag + \" \" + word]/context[next_tag])\n",
    "            else:\n",
    "                score = best_score_value -\\\n",
    "                math.log(trans[previous + \" \" + next_tag]/context[next_tag]) -\\\n",
    "                math.log(1/N)\n",
    "            if score < tmp_score:\n",
    "                tmp_score = score\n",
    "                tmp_edge = word+\" \" + previous\n",
    "    best_score['/ .'] = score\n",
    "    best_edge[\"/ .\"] = tmp_edge\n",
    "    \n",
    "    tags = []\n",
    "    next_edge = \"\"\n",
    "    for i in range(len(wordtags)):\n",
    "        if i == 0:\n",
    "            next_edge= \"/ .\"\n",
    "        if best_edge[next_edge] == None:break\n",
    "        tags.append(next_edge.split(\" \")[1])\n",
    "        next_edge = str(len(wordtags)-i-1) + \" \" + best_edge[next_edge].split(\" \")[1]\n",
    "    tags = list(reversed(tags))\n",
    "    for i in range(len(tags)):\n",
    "        denominator +=1\n",
    "        tag = tags[i]\n",
    "        real_tag = real_tags[i]\n",
    "        if tag == real_tag:\n",
    "            numerator += 1\n",
    "print(numerator)\n",
    "print(denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efa11b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 84.1%\n"
     ]
    }
   ],
   "source": [
    "print(\"acc: \" + str(round(numerator/denominator,3)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edafa07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
